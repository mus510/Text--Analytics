{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5337e7d3-bbcd-4f53-b89a-2b91ccff477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "page = requests.get(\"https://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "\n",
    "print(page.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72fc05a4-bb0c-49a3-a1cf-59f81c0e188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2f039a9-d09f-4bd7-ac3e-64b17796de58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html',\n",
       " '\\n',\n",
       " <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea9dfef-8421-4849-8025-a55f9bcfa7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b31e643-2aed-4833-ab73-b19b291ea2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<p>Here is some simple content for this page.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747dec6e-0b09-4126-b464-116ebae89a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find('p').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccad88f-8001-4bf7-a721-fac9233472bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Content: Here is some simple content for this page.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracted Content:\",content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87dd7310-6bbe-4611-a602-1cef452df66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extracted_data1.txt\",\"w\") as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12bfebf3-e72e-4be1-8fee-006a84e6a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Author: Albert Einstein\n",
      "Tags: change, deep-thoughts, thinking, world\n",
      "\n",
      "Quote: “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "Author: J.K. Rowling\n",
      "Tags: abilities, choices\n",
      "\n",
      "Quote: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Author: Albert Einstein\n",
      "Tags: inspirational, life, live, miracle, miracles\n",
      "\n",
      "Quote: “The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "Author: Jane Austen\n",
      "Tags: aliteracy, books, classic, humor\n",
      "\n",
      "Quote: “Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "Author: Marilyn Monroe\n",
      "Tags: be-yourself, inspirational\n",
      "\n",
      "Quote: “Try not to become a man of success. Rather become a man of value.”\n",
      "Author: Albert Einstein\n",
      "Tags: adulthood, success, value\n",
      "\n",
      "Quote: “It is better to be hated for what you are than to be loved for what you are not.”\n",
      "Author: André Gide\n",
      "Tags: life, love\n",
      "\n",
      "Quote: “I have not failed. I've just found 10,000 ways that won't work.”\n",
      "Author: Thomas A. Edison\n",
      "Tags: edison, failure, inspirational, paraphrased\n",
      "\n",
      "Quote: “A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "Author: Eleanor Roosevelt\n",
      "Tags: misattributed-eleanor-roosevelt\n",
      "\n",
      "Quote: “A day without sunshine is like, you know, night.”\n",
      "Author: Steve Martin\n",
      "Tags: humor, obvious, simile\n",
      "\n",
      "Quotes have been saved to quotes.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Send a GET request to the website\n",
    "page = requests.get('https://quotes.toscrape.com')\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# Create a list to store quotes\n",
    "quotes = []\n",
    "\n",
    "# Find all quote elements\n",
    "quote_elements = soup.find_all('div', class_='quote')\n",
    "\n",
    "# Extract information from each quote element\n",
    "for quote_element in quote_elements:\n",
    "    text = quote_element.find('span', class_='text').text\n",
    "    author = quote_element.find('small', class_='author').text\n",
    "\n",
    "    tag_elements = quote_element.select('.tags .tag')\n",
    "\n",
    "    tags = []\n",
    "    for tag_element in tag_elements:\n",
    "        tags.append(tag_element.text)\n",
    "\n",
    "    quotes.append({\n",
    "        'text': text,\n",
    "        'author': author,\n",
    "        'tags': ', '.join(tags)\n",
    "    })\n",
    "\n",
    "# Print the scraped quotes\n",
    "for quote in quotes:\n",
    "    print(\"Quote:\", quote['text'])\n",
    "    print(\"Author:\", quote['author'])\n",
    "    print(\"Tags:\", quote['tags'])\n",
    "    print()\n",
    "\n",
    "# Save quotes to a CSV file\n",
    "with open('quotes.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    fieldnames = ['text', 'author', 'tags']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for quote in quotes:\n",
    "        writer.writerow(quote)\n",
    "\n",
    "print(\"Quotes have been saved to quotes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "491db771-fe90-4dc2-ad90-a1c0c8b9bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv \n",
    " \n",
    "# Function to scrape quotes from a page \n",
    "def scrape_page(soup, quotes): \n",
    "    for quote in soup.find_all('div', class_='quote'): \n",
    "        text = quote.find('span', class_='text').text \n",
    "        author = quote.find('small', class_='author').text \n",
    "        tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag')) \n",
    "        quotes.append({'Text': text, 'Author': author, 'Tags': tags}) \n",
    " \n",
    "# Base URL and headers \n",
    "base_url = 'https://quotes.toscrape.com' \n",
    "headers = {'User-Agent': 'Mozilla/5.0'} \n",
    " \n",
    "# List to store quotes \n",
    "quotes = [] \n",
    " \n",
    "# Function to scrape quotes from multiple pages \n",
    "def scrape_all_pages(url): \n",
    "    while url: \n",
    "        response = requests.get(url, headers=headers) \n",
    "        soup = BeautifulSoup(response.text, 'html.parser') \n",
    "        scrape_page(soup, quotes) \n",
    "        next_page = soup.find('li', class_='next') \n",
    "        url = base_url + next_page.find('a')['href'] if next_page else None \n",
    " \n",
    "# Scrape quotes from all pages \n",
    "scrape_all_pages(base_url) \n",
    " \n",
    "# Save quotes to CSV file \n",
    "with open('quotes2.csv', 'w', newline='', encoding='utf-8') as csvfile: \n",
    "    writer = csv.DictWriter(csvfile, fieldnames=['Text', 'Author', 'Tags']) \n",
    "    writer.writeheader() \n",
    "    writer.writerows(quotes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed854fa2-f6b1-40cf-a01a-7d03512883db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein quotes saved.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "base_url = \"https://quotes.toscrape.com\"\n",
    "url = base_url\n",
    "einstein_quotes = []\n",
    "\n",
    "while url:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('div', class_='quote')\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.find('span', class_='text').text\n",
    "        author = quote.find('small', class_='author').text\n",
    "        tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag'))\n",
    "\n",
    "        if author == \"Albert Einstein\":\n",
    "            einstein_quotes.append({\n",
    "                'Text': text,\n",
    "                'Author': author,\n",
    "                'Tags': tags\n",
    "            })\n",
    "\n",
    "    next_button = soup.find('li', class_='next')\n",
    "    if next_button:\n",
    "        url = base_url + next_button.find('a')['href']\n",
    "    else:\n",
    "        url = None\n",
    "\n",
    "with open('quotes_Einstein.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['Text', 'Author', 'Tags'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(einstein_quotes)\n",
    "\n",
    "print(\"Einstein quotes saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6efbda54-8676-4ba1-84d0-fa96515dcd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life quotes saved.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "base_url = \"https://quotes.toscrape.com\"\n",
    "url = base_url\n",
    "life_quotes = []\n",
    "\n",
    "while url:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    quotes = soup.find_all('div', class_='quote')\n",
    "\n",
    "    for quote in quotes:\n",
    "        text = quote.find('span', class_='text').text\n",
    "        author = quote.find('small', class_='author').text\n",
    "        tags = ', '.join(tag.text for tag in quote.find_all('a', class_='tag'))\n",
    "\n",
    "        if \"life\" in text.lower():\n",
    "            life_quotes.append({\n",
    "                'Text': text,\n",
    "                'Author': author,\n",
    "                'Tags': tags\n",
    "            })\n",
    "\n",
    "    next_button = soup.find('li', class_='next')\n",
    "    if next_button:\n",
    "        url = base_url + next_button.find('a')['href']\n",
    "    else:\n",
    "        url = None\n",
    "\n",
    "with open('life_quotes.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['Text', 'Author', 'Tags'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(life_quotes)\n",
    "\n",
    "print(\"Life quotes saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc1717-8322-4817-8c71-25a15aff588e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
